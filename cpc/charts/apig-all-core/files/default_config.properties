########################################## coreConfig.properties start ##########################################
#CSRF_TOKEN全部请求排除用/.*
app.security.csrf-url-skip=

#mybatis自动将下划线转成小驼峰，需要关闭，不然会影响APIG的mybatis转换
ftf.mybatis.map-underscore-to-camel-case=false

#后端框架优先级低于前端框架
order.autoconfigure.main.rest=-1
#uportal/ngportal 组织的第一个节点的id, uportal值填1, ngportal值填1000000020
uportal.organization.first-node.id=1000000020

base.web.router=operator/

#redis或ctgcache配置
ftf.cache.enabled=true
ftf.cache.redis-enabled=true
ftf.cache.period=1000
ftf.cache.monitor-timeout=1000
ftf.cache.monitor-error-num=3

spring.session.redis-serializer=json
server.session.timeout=1800
server.session.cookie.name=SESSION
#ftf.cache.cache-type为redis时，指定redis数据库，默认为0
ftf.cache.database=0

#secret_key
ftf.security.encrypt.key=9lW4+lCF42wGgkBm

#门户权限校验配置
#是否是开发者模式
app.security.develop-mode=false
#是否启用菜单restful服务请求的访问控制校验
app.security.enable-acl=false
#是否启用界面元素restful服务请求的访问控制校验
app.security.enable-cacl=false
#是否启用基于角色的服务权限控制
app.security.enable-rbac=false
#静态资源过滤白名单
app.security.staticResourceMatchRuleWhiteList=/**/*.html,/**/*.js,/**/*.gif

ftf.zcm.zmq-producer-id=CRM_APIG
ftf.zcm.ctgmq.consumerId=APIG_CONSUMER
ftf.zcm.ctgmq.consumerGroupName=APIG_CONSUMER
########################################## coreConfig.properties end ##########################################



########################################## cacheConfig.properties start ##########################################

########################################## cacheConfig.properties end ##########################################



########################################## dfsConfig.properties start ##########################################
###################### DFS配置 ######################
#values： FDFS HDFS
apig.dfs.type=FDFS
###################### FastDFS配置 ######################
#客户端配置
apig.dfs.connect-timeout = 5
apig.dfs.network-timeout = 30
apig.dfs.charset = UTF-8
#连接池配置
apig.dfs.test-on-create = false
apig.dfs.test-on-borrow = true
apig.dfs.test-on-return = true
#最小空闲连接数
apig.dfs.min-idle-per-key = 0
#最大空闲连接数
apig.dfs.max_idle-per-key = 20
#最大连接数
apig.dfs.max-total-per-key = 50
#最大连接数
apig.dfs.max-total =100
###################### HDFS配置 ######################
#所连接的HDFS是否需要Kerberos认证：true/false
apig.hdfs.authorization=true
#Kerberos认证所需的Kerberos用户名， the principal name to load from the keytab(eg. gztest1)
apig.hdfs.user=bdp/admin
#Kerberos认证所需的keytab文件位置
apig.hdfs.keytab-path=C:/Users/Sekhmet/Desktop/BDP/keytab/bdp.keytab
#Kerberos认证所需的属性， java.security.krb5.realm
apig.hdfs.realm=NBDP.COM
#Kerberos认证所需的属性， java.security.krb5.kdc，多个kdc用英文逗号隔开，如host66,host67,host68
apig.hdfs.kdc=host66

######### HDFS配置--连接方式 #########
#存储空间，默认为/zop/**
apig.hdfs.path-space=/zop
#values： cluster：通过集群配置连接 uri 通过一个HDFS.uri配置连接,无需其它配置
apig.hdfs.connect-type=uri

#当HDFS.connect_type=uri时，需要配置，例如 hdfs://10.45.47.88:9000/user
apig.hdfs.uri=hdfs://10.45.47.66:8020/user

#客户端连接HDFS时，默认的路径前缀，对应core-site.xml中的fs.defaultFS属性值
apig.hdfs.fs.default-fs=hdfs://cluster1
#hadoop集群名称，对应hdfs-site.xml中的dfs.nameservices属性值
apig.hdfs.dfs.nameservices=cluster1
#namenodes名称，对应hdfs-site.xml中的dfs.ha.namenodes.[nameservice ID]属性值
apig.hdfs.dfs.namenodes=nna,nns
#namenode地址，rpc-address要与namenodes一一对应，有两个namenode就要配置两个address，用英文逗号隔开
#分别对应hdfs-site.xml中的dfs.namenode.rpc-address.[nameservice ID].[namenode ID]
#如namenodes配置了nna,nns，nna的address为10.45.47.91:9000，nns的address为10.45.47.92:9000
#则dfs.namenode.rpc-address=10.45.47.91:9000,10.45.47.92:9000，顺序不能乱
#dfs.namenode.rpc-address=10.45.47.91:9000,10.45.47.92:9000
apig.hdfs.dfs.namenode.rpc-address=10.45.47.93:9000,10.45.47.88:9000
#HDFS客户端连接到Active NameNode的一个java类，对应hdfs-site.xml中的dfs.client.failover.proxy.provider.[nameservice ID]
apig.hdfs.dfs.client.failover.proxy.provider=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
########################################## dfsConfig.properties end ##########################################



########################################## dubboConfig.properties start ##########################################
apig.dubbo.registry.group.cahce=dubbo_cache
#如果zookeeper开启sasl认证
#1、jvm参数中配置-Djava.security.auth.login.config=${user.home}/sasl.conf
#2、dubbo.registry.external=true
#3、dubbo.registry.section=Client，此属性与sasl.conf的一致，可以是其他值
#sasl.conf的内容：
#Client {
#    org.apache.zookeeper.server.auth.DigestLoginModule required
#    username="super"
#    password="{cipher}eJ8Eamr1Jax1eX4vDb7Hog==&&&&zOWDBp9mxZNcVG8WaO+sQQ==";
#};
apig.dubbo.registry.external=
apig.dubbo.registry.section=
apig.dubbo.protocol.name=dubbo
apig.dubbo.registry.protocol=zookeeper

#运营者dubbo服务提供者ip配置
apig.dubbo.operarotr.provider.ips=
#门户dubbo服务提供者ip配置
apig.dubbo.portal.provider.ips=

# Dubbo启动时qos-server can not bind localhost:22222错误解决, 并且和其他消费者模块的端口不能一样
apig.dubbo.service.qos.port=22223
apig.dubbo.operator.qos.port=22224
apig.dubbo.portal.qos.port=22225
apig.dubbo.api.qos.port=22226
apig.dubbo.dcoos.qos.port=22227
apig.dubbo.caller.qos.port=22228

uportal.dubbo.registry.protocol=zookeeper
uportal.dubbo.protocol.name=dubbo
uportal.dubbo.service.retries=0
uportal.dubbo.service.timeout=10000000
########################################## dubboConfig.properties end ##########################################



########################################## elasticsearchConfig.properties start ##########################################
#elasticsearch集群地址，多个地址用逗号分隔
apig.es.server-uri=172.21.72.110:9200
#es的用户名
apig.es.username=es_admin
#es的密码
apig.es.password=es_admin
#请求elasticsearch超时时间
apig.es.timeout=30000
#是否需要授权访问，如果es.auth=true，则需要配置用户名和密码(服务端通过shield插件配置)
apig.es.auth=false
########################################## elasticsearchConfig.properties end ##########################################



########################################## hbaseConfig.properties start ##########################################
######HBase连接基本配置
#zookeeper ip地址，多个地址则以逗号分隔
apig.hbase.zookeeper-ip=10.45.47.66
#zookeeper端口号
apig.hbase.zookeeper-port=2181
#所连接的HBase是否需要Kerberos认证：true/false
apig.hbase.authorization=true
#Kerberos认证所需的Kerberos用户名， the principal name to load from the keytab(eg. gztest1)
apig.hbase.user=gztest1
#Kerberos认证所需的keytab文件位置
apig.hbase.keytab-path=${user.home}/gztest1.keytab
#Kerberos认证所需的属性， java.security.krb5.realm
apig.hbase.realm=NBDP.COM
#Kerberos认证所需的属性， java.security.krb5.kdc，多个kdc用英文逗号隔开，如host66,host67,host68
apig.hbase.kdc=host66
#在HBase中表的初始逻辑分区数量
apig.hbase.region-count=3
#HBase命名空间，默认为default
apig.hbase.namespace=default
########################################## hbaseConfig.properties end ##########################################



########################################## jdbcConfig.properties start ##########################################
#主表
apig.jdbc.druid.encrypted=false
apig.jdbc.druid.filters=stat,config
apig.jdbc.druid.maxActive=64
apig.jdbc.druid.initialSize=5
apig.jdbc.druid.maxWait=60000
apig.jdbc.druid.minIdle=5
apig.jdbc.druid.timeBetweenEvictionRunsMillis=60000
apig.jdbc.druid.minEvictableIdleTimeMillis=300000
apig.jdbc.druid.testWhileIdle=true
apig.jdbc.druid.testOnBorrow=false
apig.jdbc.druid.testOnReturn=false
apig.jdbc.druid.poolPreparedStatements=true
apig.jdbc.druid.maxOpenPreparedStatements=20
apig.jdbc.druid.asyncInit=true

#日志表
apig.jdbc.log.druid.encrypted=false
apig.jdbc.log.druid.filters=stat,config
apig.jdbc.log.druid.maxActive=64
apig.jdbc.log.druid.initialSize=5
apig.jdbc.log.druid.maxWait=60000
apig.jdbc.log.druid.minIdle=5
apig.jdbc.log.druid.timeBetweenEvictionRunsMillis=60000
apig.jdbc.log.druid.minEvictableIdleTimeMillis=300000
apig.jdbc.log.druid.testWhileIdle=true
apig.jdbc.log.druid.testOnBorrow=false
apig.jdbc.log.druid.testOnReturn=false
apig.jdbc.log.druid.poolPreparedStatements=true
apig.jdbc.log.druid.maxOpenPreparedStatements=20
apig.jdbc.log.druid.asyncInit=true
########################################## jdbcConfig.properteis end ##########################################



########################################## kafkaConfig.properteis end ##########################################
#日志主题
apig.kafka.log-topic=chentesttopic

#broker的ip和端口，多个地址逗号隔开
apig.kafka.bootstrap-servers=172.21.72.83:9091,172.21.72.83:9092,172.21.72.83:9093

#控制默认的批量处理消息字节数
apig.kafka.batch-size=16384

#producer可以用来缓存数据的内存大小
apig.kafka.buffer-memory=33554432

#每个批量消息的最长延迟发送时间
apig.kafka.linger-ms=1

#设置每个批量消息的最长阻塞时间
apig.kafka.max-block-ms=60000

#Producer的数据确认阻塞设置
#0：表示producer不需要等待任何确认收到的信息，没有任何保障可以保证此种情况下server已经成功接收数据，同时重试配置不会发生作用。
#1：表示至少要等待leader已经成功将数据写入本地log，但是并没有等待所有follower是否成功写入。
#   这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。
#all：表示leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。-1与all相同
apig.kafka.acks=all

#消息发送失败重试的次数
apig.kafka.retries=3
########################################## kafkaConfig.properties end ##########################################



########################################## mqConfig.properties start ##########################################
#rocketmq
#客户端限制的消息大小，超过报错，同时服务端也会限制
apig.mq.rocketmq.max-message-size=1310720

#kafka
#控制默认的批量处理消息字节数
apig.mq.kafka.batch-size=16384
#producer可以用来缓存数据的内存大小
apig.mq.kafka.buffer-memory=33554432
#每个批量消息的最长延迟发送时间
apig.mq.kafka.linger-ms=1
#设置每个批量消息的最长阻塞时间
apig.mq.kafka.max-block-ms=3000
#Producer的数据确认阻塞设置
#0：表示producer不需要等待任何确认收到的信息，没有任何保障可以保证此种情况下server已经成功接收数据，同时重试配置不会发生作用。
#1：表示至少要等待leader已经成功将数据写入本地log，但是并没有等待所有follower是否成功写入。
#   这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。
#all：表示leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。-1与all相同
apig.mq.kafka.acks=all
#消息发送失败重试的次数
apig.mq.kafka.retries=3

#ctgmq
apig.mq.ctgmq.max-message-size=1310720

#拉消息间隔
apig.mq.log-pull-interval=60000
#拉消息数量
apig.mq.pull-message-size=100
#批量消费，一次消费多少条消息
apig.mq.consume-message-batch-max-size=200
#消费者工作线程数量
apig.mq.consumer-worker-size=10

#能力日志TOPIC
apig.mq.topic-interface-log=TOPIC_INTERFACE_LOG
#服务日志TOPIC
apig.mq.topic-service-log=TOPIC_SERVICE_LOG
#Nginx刷新TOPIC
apig.mq.topic-reload-nginx=TOPIC_RELOAD_NGINX
#连通性测试TOPIC
apig.mq.topic-server-telnet=TOPIC_SERVER_TELNET

#生产者实例
apig.mq.producer-instance=PRODUCER_INSTANCE
#消费者实例
apig.mq.consumer-instance=CONSUMER_INSTANCE

#能力日志生产者组
apig.mq.producer-group.interface-log=PG_INTERFACE_LOG
#服务日志生产者组
apig.mq.producer-group.service-log=PG_SERVICE_LOG
#Nginx刷新生产者组
apig.mq.producer-group.reload-nginx=PG_RELOAD_NGINX
#连通性测试生产者组
apig.mq.producer-group.server-telnet=PG_SERVER_TELNET

#能力日志写数据库消费组
apig.mq.consumer-group.interface-log-db=CG_INTERFACE_LOG_DB
#能力日志写HBase消费组
apig.mq.consumer-group.interface-log-hbase=CG_INTERFACE_LOG_HBASE
#能力日志写ES消费组
apig.mq.consumer-group.interface-log-es=CG_INTERFACE_LOG_ES
#能力日志写Hound消费组
apig.mq.consumer-group.interface-log-hound=CG_INTERFACE_LOG_HOUND
#能力日志发送kafka消费组
apig.mq.consumer-group.interface-log-kafka=CG_INTERFACE_LOG_KAFKA
#能力日志发送dcoos api 调用日志kafka消费组
apig.mq.consumer-group.interface-log-api-log=CG_INTERFACE_LOG_APILOG
#能力日志调用发送账单
apig.mq.consumer-group.interface-log-billing=CG_INTERFACE_LOG_BILLING

#服务日志写数据库消费组
apig.mq.consumer-group.service-log-db=CG_SERVICE_LOG_DB
#服务日志写HBase消费组
apig.mq.consumer-group.service-log-hbase=CG_SERVICE_LOG_HBASE
#服务日志写ES消费组
apig.mq.consumer-group.service-log-es=CG_SERVICE_LOG_ES
#服务日志写Hound消费组 apig.mq.consumer-group.service-log-hound
apig.mq.consumer-group.service-log-hound=CG_SERVICE_LOG_HOUND

#连通性测试消费者组 consumerGroupServerTelnet
apig.mq.consumer-group.server-telnet=CG_SERVER_TELNET
########################################## mqConfig.properties end ##########################################



########################################## paramConfig.properties start ##########################################
# DEFAULT_JNDI   LOG_JNDI
apig.param.jndi-name=jdbc/zopdb
apig.param.log.jndi-name=jdbc/logdb

#mybatis拦截器开关 on：开   off：关
apig.param.mybatis.interceptor.switch=off

#是否外网开发者视图
apig.param.outer-dev=F

#environ_flag:当前应用环境标识，0-生产环境，1-灰度环境
apig.param.environ-flag=0

#客户端ip在http请求头中的key
apig.param.client-ip-header=

#启动dubbo服务检查定时器的开关
apig.param.dubbo-check=false

#当前应用环境名称，P-生产，G-灰度，T-测试，D-开发
apig.param.env-name=T

#开发者视图支持的host，多个用逗号分隔，例如：10.45.47.90:8083,10.45.47.91:8084
apig.param.dev-host=

#鉴权中心的鉴权开关，true代表开启服务调用方身份权限校验，false代表不校验用户身份权限，默认false
apig.param.dcoos.authority-identify=false

# 针对沙特接口在responseHandler出现com.alibaba.fastjson.JSONException: autoType is not support的异常, 默认是关闭的(false), 开启是true
apig.param.fast-json.auto-type-support=false

# ContentSecurityAndReferrerPolicyFilter初始化配置在页面加载js、html、css等资源前，需要对资源来源进行校验，仅允许加载已知安全来源的资源
apig.param.security.csp-command=default-src 'self' 'unsafe-inline'  'unsafe-eval'
apig.param.security.rpc-command=no-referrer-when-downgrade
apig.param.security.exclude-file=

#apig是否用公共的响应, true使用，false或者不填，不使用
apig.proxy.rest.common=true
########################################## paramConfig.properties end ##########################################



########################################## quartzConfig.properties start ##########################################
#Configure Main Scheduler Properties
org.quartz.scheduler.instanceName = QuartzScheduler
org.quartz.scheduler.instanceId = AUTO

#Configure JobStore
org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX
org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate
org.quartz.jobStore.tablePrefix = qrtz_
org.quartz.jobStore.isClustered = true
org.quartz.jobStore.clusterCheckinInterval = 20000

#Configure ThreadPool
org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool
org.quartz.threadPool.threadCount = 10
org.quartz.threadPool.threadPriority = 5
org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true
########################################## quartzConfig.properties end ##########################################



########################################## redisConfig.properties start ##########################################
#哨兵模式下，master的名称
apig.redis.sentinel.master=zop
########################################## redisConfig.properties end ##########################################

